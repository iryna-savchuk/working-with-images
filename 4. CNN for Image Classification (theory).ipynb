{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2a41eb",
   "metadata": {},
   "source": [
    "### Local Receptive Fields\n",
    "\n",
    "When viewing an image, the neurons in the eye do not see the entire image. Each neuron has its own local receptive field. Thus, neurons are focusing on only a portion of the image and not the entire image, and react only to visual stimuli located in their respective fields. These neurons pass information to other neurons.\n",
    "\n",
    "The other neurons react to more complex pattrens that are combinations of lower-level patterns. (Sounds like a classic NN problem, when information is passed from one layer to another).\n",
    "\n",
    "There are 2 kinds of layers in Convolutional Neural Networks: \n",
    " - Convolution (local receptive field)\n",
    " - Pooling layer (subsampling of inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a05be",
   "metadata": {},
   "source": [
    "### Convolutional Layers\n",
    "\n",
    "**Convolution layer** - the layer that allows the neurons to focus on a local receptive field and react to visual stimuli in that field. \n",
    "\n",
    "In this context, **convolution** refers to a Mathematical function, which is basically a sliding window function that is applied to a matrix (the matrix of pixels representing an imput image). This sliding window function is applied to extract features and is often called a *kernel* or a *filter*. \n",
    "\n",
    "The kernel/filter is associated with weights, and these weights are what help this kernel extract specific kind of features, detect edges, corners, lines, etc. Kernel is applied element-wise in sliding-window fasion on both horizontal and vertical strides. And both the horizontal stride and the vertical stride are hyper-parameters of the convolutional layer. \n",
    "\n",
    "The convolution kernel is applied to every channel of the input image separately. So, if you have a multi-channel image, the convolution kernel will slide over the matrix for each channel.\n",
    "\n",
    "Convolutional layers:\n",
    "\n",
    " - Zoom in on specific bits of input;\n",
    " - Extract structure and features in the input image;\n",
    " - Successive layers agregate inputs into higher level features;\n",
    " - Pixels >> Lines >> Edges >> Object\n",
    " \n",
    "The result of the convolutional layer is a **feature map**. The feature map, which is the result of applying a convolutional kernel to the input, can be thought of as made up of neurons that are reacting to the local receptive field of the input. All neurons in a feature map generated using the same kernel have the same weights and biases. The different feature maps have different parameters and they extract different features. \n",
    "\n",
    "Convolutional kernel size is usually expressed in terms of width and height of the receptive area. In practice, it is more efficient to use small convolutional kernels: stacking two 3 * 3 kernels is preferable to having one 9 * 9 kernel. \n",
    " \n",
    "**Stride** is a distance between successive receptive fields. The lenth of the stride is another hyperparameter of the convolutional layer (zero padding may be needed in the edges of the image). There are horizonal and vertical strides and they can be set separately. The resulting fature map is almost always smaller than the input matrix (because kernal size is greater than 1).\n",
    "\n",
    "Interconnections between layers are, thus, sparse, not dense. CNNs are sparse NNs. \n",
    "\n",
    "Two big advantages of CNNs over DNNs because of convolutional layers:\n",
    "1. Dramatically fewer parameters to train\n",
    "2. CNNs can recognize feature patterns independent of location (location invariance)\n",
    "\n",
    "Convolutional layer can be thought as a stack of several feature maps of equal sizes which extract different features from the input image (so, the convolutional layer has depth). A CNN is made up of many such convolutional layers. \n",
    "\n",
    "**Feature map size calculation**\n",
    "\n",
    "To calculate output dimention (height or width of an output), it is possible to use the following formula:\n",
    "\n",
    "Output_dimention = (Input_dimention - Kernel_size + 2 Paddings)/Stride_size + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94d8ff",
   "metadata": {},
   "source": [
    "### Pooling Layers\n",
    "\n",
    "**Pooling layers** - layer where a kind of aggregation operation to the input. This aggregation can be the max aggregation or sum, or, for example, an average pooling. The result of the pooling layer is much smaller that the input image matrix. \n",
    "\n",
    "The pooling filter can be seen as a filter with no weight and biases, it only performs an aggregation. \n",
    "\n",
    "Why to use ppoling layers? \n",
    "- Greately reduce memory usage during training\n",
    "- Mitigate overfitting (via subsampling)\n",
    "- Make NN recognize features independent of location (location invariance)\n",
    "\n",
    "Pooling layers typically act on each channel independantly, so if you have multi-channel RGB image, a pooling filter will be applied to eahc of the input channels. \n",
    "\n",
    "Usually, output area < input area, but output depth = input depth. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b672e",
   "metadata": {},
   "source": [
    "### Typical CNN architecture\n",
    "\n",
    "Input to CNN is a batch of images and typically, CNN architecture comprises of **alternating groups of convolutional and pooling layers**. \n",
    "\n",
    "Different architectures have different designs. There are designs with multiple convolutional layers stacked together and followed by a pooling layer, but the alternating groups of convolutionals and pooling layers is a standard pattern in CNNs. Also, each group of convolutional layers is usually followed by a **ReLU activation** layer. \n",
    "\n",
    "It's often being the case that between the convolutional layer and ReLU activation layer you might apply **batch normalization**. Batch normalization involves shifting and scaling the output of your convolutional layer around 0 and can improve the perfomance of the network. \n",
    "\n",
    "The output of each layer in CNN is also an image (matrix): convolutional layers output images and pooling layers output images. However, successive outputs become smaller and smaller (due to pooling layers). Besides, the results generated by successive layers also get deeper and deeper (due to the presence of feature maps in each convolutional layer).\n",
    "\n",
    "After passing through all of the convolutional and pooling layers, you get a much deeper and smaller output, which now can be fed into a regular **feed-forward NN** (a fully connected NN with ReLU activation). The fully connected NN will have a final output layer which emmits probabilities for different categories (**SoftMax Prediction Layer** or a Log SoftMax prediction).\n",
    "\n",
    "So, the input to a CNN is an image and theoutputs are probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0b4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
